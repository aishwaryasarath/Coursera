Cloud services overview
----------
So when we say that a service is running in the Cloud, what do we actually mean? It has nothing to do with those white fluffy things in the sky, it simply means that the service is running somewhere else either in a data center or in other remote servers that we can reach over the Internet. These data centers house a large variety of machines, different types of machines are used for different services. For example, some machines may have local solid-state drive or SSD, for increased performance while others may rely on virtual drives mounted over the network to lower costs. Cloud providers typically offer a bunch of different service types, the ones used most by users are in the Software as a Service category. Software as a Service or SaaS, is when a Cloud provider delivers an entire application or program to the customer. If you choose a Cloud e-mail solution like Gmail, a Cloud storage solution like Dropbox, or a Cloud productivity suite like Microsoft Office 365, there are only a small number of options for you to select or customize. The Cloud provider manages everything related to the service for you including deciding where it's hosted, ensuring the service has enough capacity to serve your needs, performing backups frequently and reliably, and a lot more. There's a lot of software being offered as a service by many different Cloud providers or other Internet companies. But of course, not all of our needs can be solved by prepackaged software, sometimes we need to develop our own. For some of the components of our software, we might choose to use Platform as a Service. Platform as a Service or PaaS, is when a Cloud provider offers a preconfigured platform to the customer. When we say platform here, it can be a bit confusing because there are lots of different platforms that exist under a PaaS model. Let's check out an example to understand this better. Say you need an SQL database to store some of your applications data, you could choose to host the database in your own hardware. To do this, you'd need to install an operating system on that computer and then install the SQL software on top of the chosen OS. This requires a basic understanding of all of these different pieces just to get the database running. There's a bunch of things that could go wrong and even if you can eventually solve all of them, it can take awhile. Instead, you could decide to use a Cloud provider that offers an SQL database as a service, that way you can just focus on writing SQL queries and using the platform, and let the Cloud provider take care of the rest. There's a bunch of different platforms offered as a service by Cloud providers, but of course they are unlikely to cover all of your needs. If you need a high level of control over the software you're running and how it interacts with other pieces in your system, you might want to choose Infrastructure as a Service. Infrastructure as a Service or IaaS, is when a Cloud provider supplies only the bare-bones computing experience. Generally, this means a virtual machine environment and any networking components needed to connect virtual machines, the Cloud provider won't care what you're using the VMs for. You could use them to host a web server, a mail server, your own SQL database with your own configuration settings, or a whole lot more possibilities. Running your IT infrastructure on the Cloud provider's IaaS offering is a very popular choice. There's a lot of different providers out there, big and small that offer a service where you can run virtual machines in their Cloud. Some IaaS products include: Amazon's EC2, Google Compute Engine, and Microsoft Azure Compute. Now no matter the service model and the provider you use, when you set up Cloud resources you'll need to consider regions. A region is a geographical location containing a number of data centers, regions contain zones and zones can contain one or more physical data centers. If one of them fails for some reason, the others are still available and services can be migrated without notably affecting users. Large Cloud providers usually offer their services in lots of different regions around the world. Generally, the region and zone you select should be closest to your users, the further your users are from the physical data center the more latency they may experience. This might sound a bit strange but imagine if you are on vacation overseas, you might notice that your bank website loads a little slower. That's why it's common practice to locate data centers close to where users actually live, work, and bank. Latency isn't the only factor to take into account when selecting a region or zone, some organizations require their data to be stored in specific cities or countries for legal or policy reasons. If your service uses other services as dependencies, it's a good idea to host the service physically close to its dependencies. For example, if a mail server requires a database server to send an e-mail, it makes sense to host the database server and the mail server in the same zone. Recall that earlier, that Qwiklabs is a service using Cloud infrastructure. So what kind of Cloud service does Qwiklabs use? Qwiklabs uses Infrastructure as a Service, the VMs get provisioned with just the OS and the lab automation then deploys any additional files and software into the OS. Up next, we'll talk about how we can use the services offered by Cloud providers to help us scale our applications.

Scaling in the Cloud
-------
One of the coolest features of deploying solutions to the Cloud is how easily and quickly we can scale our deployments. In a traditional IT setting, if your team needs an extra server to improve the service, you need to buy additional hardware, install the operating system and application software and then integrate the new computer with the rest of the infrastructure. Doing all of these takes time so it's not easy to quickly scale up or down if the service gets more or less usage. In other words, it takes a significant amount of time to modify the capacity of the deployment. In this context, capacity is how much the service can deliver. The available capacity is tied to the number and size of servers involved. We get more capacity by adding more servers or replacing them with bigger servers. The way we measure the capacity of a system depends on what the system is doing. If we're storing data, we might care about the total disk space available. If we have a web server responding to queries from external users, we might care about the number of queries that can be answered in a second which is called queries per second or QPS. Or maybe the total bandwidth served in an hour. We can measure capacity in other fun ways like the number of cat videos served in an hour or the number of digits of pi a system can calculates. Our capacity needs can change over time. Say you're hosting an e-commerce site that needs a hundred servers to meet user demands. As the service becomes more popular, demand might grow and you'll need to increase the available capacity. Eventually, the system could need a thousand servers to meet user demands. This capacity change is called scaling. In particular, we call it upscaling when we increase our capacity and downscaling when we decrease it. This could happen for example if the demand for a product decreased or if the system was improved to need fewer resources. Cloud providers typically have a lot of available capacity that can be used by their customers. When we choose to host our infrastructure in the Cloud, we're purchasing and using some of the providers capacity to supplement or completely replace our on-premise capacity. This lets us easily scale our service to satisfy demand. There are a couple of different ways that we can scale our service in the Cloud, horizontally and vertically. To scale a deployment horizontally, we add more nodes into the pool that's part of a specific service. Say your web service is using Apache to serve web pages. By default, Apache is configured to support a 150 concurrent connections. If you want to be able to serve 1,500 connections at the same time, you can deploy 10 Apache web servers and distribute the load across them. This is called horizontal scaling. You add more servers to increase your capacity. If the traffic goes up you could just add more servers to keep up with it. On the flip side, if you're scaling a deployment vertically, it means you're making your nodes bigger. When we say bigger here we're talking about the resources assigned to the nodes like memories, CPU, and disk space. For example, a database server with a 100 gigabytes of disk space can store more data than with only 10 gigabytes of space. To scale this deployment we can just add a bigger disk to the machine and the same idea works for a CPU and memory too. Say you have a caching server and you notice it's using 95 percent of the available memory. You can deal with that by adding more memory to the node. Depending on our deployment and our needs, we might need to scale both horizontally and vertically to scale the capacity of our service. In other words, adding more and bigger nodes to our pool. This approach to scaling isn't too different from what you'd need to do if you have your servers running on-premise. Instead of sending someone to change the physical deployment, for example adding more physical RAM to a server or adding 10 more physical machines in a server rack, we just modify our deployment by clicking some buttons in a web UI or using a configuration management system to automate the scaling for us. The infrastructure built by the Cloud provider will deploy any additional resources we need. When talking about scaling in the Cloud, another aspect we need to take into account is whether the scaling is done automatically or manually. When we set our service to use automatic scaling, we're using a service offered by the Cloud provider. This service uses metrics to automatically increase or decrease the capacity of the system. Say you have a system that currently has the capacity to serve 1,000 cat videos per minutes. If the demand for these videos increases to 10,000 per minute and it will, the software in-charge of the automatic scaling will add resources and increase the overall capacity to meet this demand. When the users stop watching cat videos, the automation will remove any unused resources, so the operating costs stay small. But really who wants to stop watching cat videos? But make sure you set a reasonable quotas for your autoscaling systems. Otherwise, that viral video of a cute cat wearing a hat might surprise you with a very uncute big bill from your Cloud provider. On the flip side, using manual scaling means that changes are controlled by humans instead of software. Manual scaling has its pros and cons too. When the Cloud deployment isn't very complex, it's usually easier for smaller organizations to use manual scaling practices. Say your company currently has a single mail server and you know that you'll want to have another one in six months. In that case, there's no need to overcomplicate that system with an autoscaler. You could simply add the extra server sometime along the way. The trade-off here is that without good monitoring or alerting, a system without autoscaling technologies might suffer from unexpected increases in demand. If you're using manual scaling for a service that becomes popular and demand grows quickly, you might not be able to increase the capacity quickly enough. This can store up lots of problems ranging from poor performance to an actual outage. In this video, we've covered concepts that are central to any solution hosted in the Cloud like capacity and scaling. As you probably noticed, Cloud technology offers a ton of benefits for an IT team. But it also can be a little intimidating. Up next, we'll go into some of the reasons why IT teams might be hesitant to migrate to the Cloud and how to overcome those fears.


 evaluating the cloud
 -------
 If you've always worked in a traditional IT environment with servers that are physically owned by your company, the idea of migrating to the cloud can be pretty scary. When you're running the service yourself, if something breaks, you can either physically walk up to the server to fix it or SSH into it from inside the same network. You can apply a quick fix and have your users back to being productive in no time.
Start transcript at 30 seconds0:30
As part of the IT team, you own the hardware, software, the network connections, and anything in between, which lets you have a lot of control over what's going on in the whole system. In the case of cloud solutions, we need to give up some of this control to the cloud provider.
Start transcript at 46 seconds0:46
We have different levels of control depending on the service model that we choose, whether that's software, platform, or infrastructure as a service. When choosing to use software as a service, we're basically giving the provider complete control of how the application runs. We have a limited amount of settings that we can change, but we don't need to worry about making the system work. This can be a great option when the software provided fulfills all of our needs and we'd rather just focus on using the software instead. But as we called out, there's only a limited amount of applications being offered in such a prepackaged way. If we need to create our own applications, we can use platform as a service. With this option, we're in charge of the code, but we aren't in control of running the application. Or we can choose infrastructure as a service, where we can still keep a high level of control. We decide the operating system that runs on the virtual machines, the applications that are installed on it, and so on. We'll still depend on the vendor for other aspects of the deployment, like the network configuration or the services availability. If something does break, you might need to get support from the vendor to fix the problem. So when choosing a cloud provider, it's important to know what kind of support is available and select the one that fits your needs. I know it sounds strange to give away your control over the hardware, and the network, and the overall infrastructure. But personally, I find that it's pretty great to not have to worry about maintaining the machines that are running our services. It means we can treat the servers executing the workloads as a commodity, instead of special snowflakes. One aspect that might make you hesitant to move to the cloud is that you don't know exactly what security measures are being put in place. So when selecting which provider to use, it's important that you check how they're keeping your instances and your data secure. There are a bunch of certifications like SOC 1, ISO 27001, and other industry recognized credentials that you can look for to verify that your provider has invested in security. Once you're sure that your provider is taking the right security measures, it might be tempting to just leave security to the professionals and forget about it. But as cloud users, we also have a responsibility to follow reasonable security practices. Google, Amazon, Microsoft, and other cloud providers invest heavily in security research. But that won't matter if the root password of your cloud instance password one or the instance doesn't use a firewall. In other words, we should always use reasonable judgment to protect the machines that we deploy ,whether that's on physical server is running on-premise or on virtual machines in the Cloud. It's also important to keep in mind that security systems can be expensive to implement correctly. Some highly sensitive deployments might warrant specialized security procedures, like multi-factor authentication, encrypted file systems, or public key cryptography. But these processes can also be expensive to implement. It's worth considering if using these techniques is necessary for your specific use case. If your application stores recent patient health records, that's super important data that needs to be protected. You want to apply the most stringent security practices. But if you're dealing with patient health records from the 1800s, you'll need less comprehensive security measures, since this data is much less sensitive, given its age. There's a bunch of other reasons why you might have doubts about cloud providers. For example, you might be worried of where your data is going to be stored. Or you might fear that the support offered won't satisfy your needs. No matter the reason, It's important that you carefully read the terms of service to understand the conditions and figure out if the service offered will satisfy your needs. In a way, cloud services are a little like actual clouds. They come in all different shapes and sizes. And sometimes a dark stormy one comes along to rain on your productive day.
Start transcript at 4 minutes 49 seconds4:49
But if you prepare an advance with the right security measures and maybe an umbrella, working in the cloud will be nothing but a breeze. So let's say you've decided to migrate part of your infrastructure to the cloud. What do you do next?
Start transcript at 5 minutes 3 seconds5:03
Migrating to the cloud is a big topic, and it's coming up in our next video.


migrating to the cloud
-------
0:07
A lot of companies today are looking into migrating at least part of their IT infrastructure to the Cloud. The details of the migration will depend on what your infrastructure currently looks like, and what you're trying to achieve by migrating to a Cloud provider. In general, we're looking at a trade-off between how much control we have over the computers providing the services and how much work we need to do to maintain them. We've called out that when we use Infrastructure as a Service or IaaS, we deploy our services using virtual machines running on the Cloud providers infrastructure. We have a lot of control over how the infrastructure is designed which can be super useful. For example, we can decide which of the many available machine types to use and what kind of storage to attach to them. IaaS is especially useful to administrators using a lift and shift strategy. So what does that mean? Say you work at a small organization that's expanding. As the company grows, physical space for employees; desks, ping pong tables, and printers becomes scarce. Eventually, the whole office might need to move to a larger space. This means moving not just the desks and printers, but also any servers running on-premise. If physical servers need to be moved, you might need to take a server from the old office, turn it off during a maintenance window, load it onto a truck, and physically drive it to the new location. This could be the new office or maybe even a small data center. So you're literally lifting the server and moving it to a new location, that's where the lift in lift and shift comes from. When migrating to the Cloud, the process is somewhat similar. But instead of moving the physical server in the back of a truck, you migrate your physical servers running on-premise to a virtual machine running in the Cloud. In this case, you're shifting from one way of running your servers to another. The key thing to note with both approaches, is that the servers core configurations stay the same. It's the same software that needs to be installed on the machine to provide its functionality, no matter if the server is hosted physically on-site or virtually in the Cloud. If you've already been using configuration management to deploy and configure your physical servers, moving to a Cloud setup can be pretty easy. You just have to apply the same configuration to the VMs that are running in the Cloud and you'll have replicated the setup. On the flip side, using this strategy means that you still have to install and configure the applications yourself. You need to make sure that both the OS and the software stay up to date, that no functionality breaks when they get updated, and a bunch of other things depending on which specific application the server is running. One alternative in this case is using Platform as a Service or PaaS. This is well-suited for when you have a specific infrastructure requirement, but you don't want to be involved in the day-to-day management of the platform. In an earlier video, we mentioned the example of an SQL database that could be used in this way. By leaving the management of the database to the Cloud provider, you don't need to worry about having the right disks attached to the computer, configuring the database or any other task related to the machine setup. Instead, you can focus on just using the database. Another example of Platform as a Service are managed web applications. When using this service, you only have to care about writing the code for the web app. You don't need to care about the framework for running it. This can accelerate development because developers don't have to spend time managing the platform and can just focus on writing code. Some popular managed web application platforms include Amazon Elastic Beanstalk, Microsoft App Service, and Google App Engine. While these platforms are very similar, they aren't fully compatible. So migrating from an on-premise framework and switching between vendors will require some code changes. Another related concept that you might have heard of is containers. Containers are applications that are packaged together with their configuration and dependencies. This allows the applications to run in the same way no matter the environment used to run them. In other words, if you have a container running an application, you can deploy it to your on-premise server, to a Cloud provider, or a different Cloud provider. Whichever you choose, it will always run in the same way. This makes migrating from one platform to the other super easy. When talking about migrating to the Cloud, you may also hear about public Clouds, private Clouds, hybrid Clouds, and multi-Clouds. Let's check out what each of these mean. We call public Cloud the Cloud services provided to you by a third party. It's called public because Cloud providers offer services to, you guessed it, the public. A private Cloud is when your company owns the services and the rest of your infrastructure, whether that's on-site or in a remote data center. It's private because it's just for your company, like having your own Cloud in the sky. A hybrid Cloud is a mixture of both public and private Clouds. In this scenario, some workloads are run on servers owned by your company, while others are run on servers owned by a third party. The trick to making the most of the hybrid Cloud is ensuring that everything is integrated smoothly. This way, you can access, migrate, and manage data seamlessly no matter where it's hosted. Finally, multi-Cloud is a mixture of public and/or private Clouds across vendors. For example, a multi-Cloud deployment may include servers hosted with Google, Amazon, Microsoft, and on-premise. A hybrid Cloud is simply a type of multi-Cloud, but the key difference is that multi-Clouds will use several vendors, sometimes in addition to on-site services. Using multi-Clouds can be expensive, but it gives you extra protection. If one of your providers has a problem, your service can keep running on the infrastructure provided by a different provider. In the last few videos, we've covered a lot of different concepts related to Cloud infrastructure, Cloud services, and how we can use them to scale in the Cloud. Coming up, we've got a quiz to check that all of these concepts are making sense. After that, we'll look into how using Cloud infrastructure looks in practice.
